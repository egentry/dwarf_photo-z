{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# What do I want?\n",
    "\n",
    "Previously in `HSC_COSMOS_filtering.ipynb` I tested out some basic classifiers to get a smaller sample set, while still keeping completeness high.  I tested two basic classifiers: a RandomForest classifier and a Logistic Regression classifier.\n",
    "\n",
    "For my training data, I started by getting objects and labels from COSMOS. For input features, I then matched those COSMOS galaxies to their nearest HSC counterpart. I then used HSC i-band magnitude, along with HSC g-r, r-i, i-z, z-y colors.\n",
    "\n",
    "Choosing some arbitrary thresholds, I got similar results for the Random Forest and the Logistic Regression classifiers. In this notebook I'll look at the full ROC curves for both classifiers, in hopes of better understanding my results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import datasets\n",
    "from matching import Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "COSMOS = datasets.COSMOS(\"COSMOS_reference.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HSC = datasets.HSC(\"HSC_COSMOS_median_forced.sqlite3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "COSMOS.df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HSC.df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "downsample_factor_COSMOS = 1\n",
    "mask_COSMOS_downsample = (COSMOS.df.index % downsample_factor_COSMOS == 0)\n",
    "\n",
    "downsample_factor_HSC = 1\n",
    "mask_HSC_downsample = (HSC.df.index % downsample_factor_HSC == 0)\n",
    "\n",
    "\n",
    "matches = Matches(COSMOS,\n",
    "                  HSC,\n",
    "                  mask_catalog_1=mask_COSMOS_downsample,\n",
    "                  mask_catalog_2=mask_HSC_downsample,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "low_z = (matches.catalog_1.df[matches.mask_catalog_1].photo_z < .15)\n",
    "low_mass = (matches.catalog_1.df[matches.mask_catalog_1].mass_med < 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Create classification labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Class A: matched **and** (low redshift + low mass)\n",
    "\n",
    "Class B: matched **but not** (low redshift + low mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class_a = matches.mask_match & (low_z & low_mass)\n",
    "class_b = matches.mask_match & ~(low_z & low_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "idxs = matches.idx[class_a.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class_a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class_b.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class_a.sum() / (class_a.sum() + class_b.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class_b.sum() / (class_a.sum() + class_b.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "matches.catalog_2.df[\"low_z_low_mass\"] = False\n",
    "# only change the flag if the object has been matched to, and if it is in class_a\n",
    "matches.catalog_2.df.loc[matches.catalog_2.df.index[matches.mask_catalog_2][idxs],\n",
    "                         [\"low_z_low_mass\"]] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# this is different from `class_a.mean()`\n",
    "# because COSMOS galaxies (which `class_a` referred to)\n",
    "# don't have a 1-to-1 map to HSC galaxies, even if they map\n",
    "# (we expect ~2 HSC galaxies to map to a given COSMOS galaxy, on average)\n",
    "\n",
    "# why this is lower, rather than higher, I don't know\n",
    "matches.catalog_2.df[\"low_z_low_mass\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "matches.catalog_2.df.low_z_low_mass.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Create a dataframe of just the matched galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "matched_hsc = matches.catalog_2.df[matches.mask_catalog_2].iloc[matches.idx[matches.mask_match]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "matched_hsc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "matched_hsc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Turn fluxes into rough colors\n",
    "Yes, I know these aren't exactly the right colors since I'm not including zero-points, but that shouldn't affect the results.\n",
    "\n",
    "(When I get a chance, I'll re-download the dataset so that it includes magnitudes not just fluxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "matched_hsc[\"g_minus_r\"] = -.4*np.log10(matched_hsc[\"gcmodel_flux\"] / matched_hsc[\"rcmodel_flux\"])\n",
    "matched_hsc[\"r_minus_i\"] = -.4*np.log10(matched_hsc[\"rcmodel_flux\"] / matched_hsc[\"icmodel_flux\"])\n",
    "matched_hsc[\"i_minus_z\"] = -.4*np.log10(matched_hsc[\"icmodel_flux\"] / matched_hsc[\"zcmodel_flux\"])\n",
    "matched_hsc[\"z_minus_y\"] = -.4*np.log10(matched_hsc[\"zcmodel_flux\"] / matched_hsc[\"ycmodel_flux\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For now, filter out bad photometry. Later I could consider passing this into the classifier, as an imputed/sentinel value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mask =    np.isfinite(matched_hsc[\"g_minus_r\"]) & np.isfinite(matched_hsc[\"r_minus_i\"]) \\\n",
    "        & np.isfinite(matched_hsc[\"i_minus_z\"]) & np.isfinite(matched_hsc[\"z_minus_y\"]) \\\n",
    "        & np.isfinite(matched_hsc[\"icmodel_flux\"]) \\\n",
    "        & (~matched_hsc.gcmodel_flux_flags) & (~matched_hsc.rcmodel_flux_flags) \\\n",
    "        & (~matched_hsc.icmodel_flux_flags) & (~matched_hsc.zcmodel_flux_flags) \\\n",
    "        & (~matched_hsc.ycmodel_flux_flags)\n",
    "\n",
    "matched_hsc = matched_hsc[mask]\n",
    "\n",
    "matched_hsc[\"log_icmodel_flux\"] = np.log10(matched_hsc[\"icmodel_flux\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "matched_hsc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "features = matched_hsc.loc[:,[\"g_minus_r\", \"r_minus_i\", \"i_minus_z\", \"z_minus_y\",\n",
    "                              \"log_icmodel_flux\"]]\n",
    "\n",
    "target = matched_hsc.loc[:,[\"low_z_low_mass\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "target.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Build Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Partition training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "testing_fraction = .1\n",
    "test_set_indices = np.random.choice(target.index.values, \n",
    "                                    replace=False,\n",
    "                                    size=int(testing_fraction*target.size)\n",
    "                                   )\n",
    "\n",
    "training_set_indices = np.array(list(set(target.index.values) - set(test_set_indices)))\n",
    "\n",
    "features_train = features.loc[training_set_indices]\n",
    "features_test  = features.loc[test_set_indices]\n",
    "\n",
    "target_train   = target.loc[training_set_indices]\n",
    "target_test    = target.loc[test_set_indices]\n",
    "\n",
    "true_a =  target_test.values.flatten()\n",
    "true_b = ~target_test.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_classification_characteristics(target_prob, threshold_prob, verbose=False):\n",
    "\n",
    "    target_prediction = (target_prob > threshold_prob)\n",
    "    \n",
    "    prediction_a =  target_prediction\n",
    "    prediction_b = ~target_prediction\n",
    "    \n",
    "    completeness = (true_a & prediction_a).sum() / (true_a).sum() \n",
    "    \n",
    "    purity = (true_a & prediction_a).sum() / (prediction_a).sum() \n",
    "    \n",
    "    sample_size_reduction = prediction_a.size / prediction_a.sum()\n",
    "    \n",
    "    true_positives  = np.sum(true_a & prediction_a)\n",
    "    false_positives = np.sum(true_b & prediction_a)\n",
    "    \n",
    "    true_negatives  = np.sum(true_b & prediction_b)\n",
    "    false_negatives = np.sum(true_a & prediction_b)\n",
    "    \n",
    "    true_positive_rate = true_positives / true_a.sum()\n",
    "    false_positive_rate = false_positives / true_b.sum()\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"completeness:          \", completeness)\n",
    "        print(\"purity:                \", purity)\n",
    "        print(\"sample_size_reduction: \", sample_size_reduction)\n",
    "        print(\"true  positive rate:   \", true_positive_rate)\n",
    "        print(\"false positive rate:   \", false_positive_rate)\n",
    "        \n",
    "    return {\n",
    "        \"completeness\": completeness,\n",
    "        \"purity\": purity,\n",
    "        \"sample_size_reduction\": sample_size_reduction,\n",
    "        \"threshold_prob\": threshold_prob,\n",
    "        \"true_positive_rate\": true_positive_rate,\n",
    "        \"false_positive_rate\": false_positive_rate,\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier_RF = RandomForestClassifier()\n",
    "classifier_RF = classifier_RF.fit(features_train, target_train.values.flatten())\n",
    "\n",
    "target_prob_RF = classifier_RF.predict_proba(features_test)[:,1]\n",
    "print(\"min prob: \", target_prob_RF.min())\n",
    "print(\"max prob: \", target_prob_RF.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_classification_characteristics(target_prob_RF, .01, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "threshold_probs = np.linspace(0, 1, num=100)[1:-1]\n",
    "results_RF = [get_classification_characteristics(target_prob_RF, threshold_prob)\n",
    "              for threshold_prob in threshold_probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "completenesses_RF         = [result[\"completeness\"] for result in results_RF]\n",
    "purities_RF               = [result[\"purity\"] for result in results_RF]\n",
    "sample_size_reductions_RF = [result[\"sample_size_reduction\"] for result in results_RF]\n",
    "true_positive_rates_RF    = [result[\"true_positive_rate\"] for result in results_RF]\n",
    "false_positive_rates_RF   = [result[\"false_positive_rate\"] for result in results_RF]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier_LR = LogisticRegression(class_weight=\"balanced\")\n",
    "classifier_LR = classifier_LR.fit(features_train, np.array(target_train.values.flatten(), dtype=int))\n",
    "\n",
    "target_prob_LR = classifier_LR.predict_proba(features_test)[:,1]\n",
    "print(\"min prob: \", target_prob_LR.min())\n",
    "print(\"max prob: \", target_prob_LR.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_classification_characteristics(target_prob_LR, .01, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "threshold_probs = np.linspace(0, 1)[1:-1]\n",
    "results_LR = [get_classification_characteristics(target_prob_LR, threshold_prob)\n",
    "              for threshold_prob in threshold_probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "completenesses_LR         = [result[\"completeness\"] for result in results_LR]\n",
    "purities_LR               = [result[\"purity\"] for result in results_LR]\n",
    "sample_size_reductions_LR = [result[\"sample_size_reduction\"] for result in results_LR]\n",
    "true_positive_rates_LR    = [result[\"true_positive_rate\"] for result in results_LR]\n",
    "false_positive_rates_LR   = [result[\"false_positive_rate\"] for result in results_LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "# Get specific galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "best_dwarfs_args  = np.argpartition(target_prob_RF, target_prob_RF.size-100)[-100:]\n",
    "worst_dwarfs_args = np.argpartition(target_prob_RF, 100)[:100]\n",
    "\n",
    "best_dwarfs_ids  = target_test.iloc[best_dwarfs_args].index\n",
    "worst_dwarfs_ids = target_test.iloc[worst_dwarfs_args].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "random_ids = np.random.choice(training_set_indices,\n",
    "                              replace=False,\n",
    "                              size=100,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Do they give reasonable dwarf fractions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "matched_hsc.loc[best_dwarfs_ids].low_z_low_mass.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "matched_hsc.loc[worst_dwarfs_ids].low_z_low_mass.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "matched_hsc.loc[random_ids].low_z_low_mass.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Save the indices to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"quick_sample/ids_best.csv\",   best_dwarfs_ids,  fmt=\"%d\")\n",
    "np.savetxt(\"quick_sample/ids_worst.csv\",  worst_dwarfs_ids, fmt=\"%d\")\n",
    "np.savetxt(\"quick_sample/ids_random.csv\", random_ids,       fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# What image size do I need?\n",
    "\n",
    "For this, you'll need to use `data.get_shapes.ipynb` to query + store the object shapes from the remote database."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
