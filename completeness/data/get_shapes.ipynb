{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation\n",
    "\n",
    "In `get_fluxes.ipynb` I used a sql query that downloaded the position and fluxes of every HSC object in the COSMOS field (pdr1, median seeing, forced table).  From there, I created a basic classifier that gave a rough probability of a particular galaxy being low-mass and low-redshift.  I saved the ids of the best 100 candidates as the \"best\" sample; the worst 100 candidates were saved as the \"worst\" sample; another 100 candidates were randomly chosen (from the training set) as the \"random\" sample.\n",
    "\n",
    "Unfortunately, I have no information about the size of these galaxies, so I don't know how big their postage stamps should be. This notebook takes in the ids of each dataset, queries the remote database on their shapes, and saves the results locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Code\n",
    " **Remember to set your credentials within `hsc_credentials.py` !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from hsc_credentials import credential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from hscReleaseQuery import query_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = glob.glob(\"../quick_sample/*.csv\")\n",
    "filenames_dict = {os.path.basename(filename).replace(\".csv\",\"\").replace(\"ids_\",\"\") :  filename\n",
    "                 for filename in filenames}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_query_from_ids_filename(ids_filename):\n",
    "    ids = np.loadtxt(ids_filename, dtype=int)\n",
    "    ids = sorted(ids)\n",
    "    \n",
    "    ids_str = \"\"\n",
    "    for id in ids:\n",
    "        ids_str += \"    {:d},\\n\".format(id)\n",
    "    ids_str = ids_str.rstrip(\",\\n\")\n",
    "    \n",
    "    shapes_sql = \"\"\"\n",
    "SELECT \n",
    "    object_id, \n",
    "    ra, dec,\n",
    "    gshape_sdss_11, gshape_sdss_22, gshape_sdss_12, gshape_sdss_flags,\n",
    "    rshape_sdss_11, rshape_sdss_22, rshape_sdss_12, rshape_sdss_flags,\n",
    "    ishape_sdss_11, ishape_sdss_22, ishape_sdss_12, ishape_sdss_flags,\n",
    "    zshape_sdss_11, zshape_sdss_22, zshape_sdss_12, zshape_sdss_flags,\n",
    "    yshape_sdss_11, yshape_sdss_22, yshape_sdss_12, yshape_sdss_flags\n",
    "FROM\n",
    "    pdr1_cosmos_widedepth_median.forced\n",
    "WHERE\n",
    "    object_id IN (\n",
    "{}\n",
    "    ) \"\"\".format(ids_str)\n",
    "    \n",
    "    return shapes_sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Make the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for label in filenames_dict:\n",
    "    shapes_sql = build_query_from_ids_filename(filenames_dict[label])\n",
    "    \n",
    "    preview_results = False\n",
    "    delete_job = True\n",
    "    out_format = \"sqlite3\"\n",
    "    \n",
    "    output_filename = \"shapes_{}.sqlite3\".format(label)\n",
    "    print(output_filename)\n",
    "\n",
    "    with open(output_filename, mode=\"wb\") as output_file:\n",
    "        query_wrapper(credential, shapes_sql, preview_results, delete_job, \n",
    "                      out_format, output_file,\n",
    "                      nomail=True,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check if it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!ls -lh shapes_*.sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_best = pd.read_sql_table(\"table_1\", \n",
    "                            \"sqlite:///{}\".format(\"shapes_best.sqlite3\"), \n",
    "                            index_col=\"object_id\")\n",
    "\n",
    "df_worst = pd.read_sql_table(\"table_1\", \n",
    "                            \"sqlite:///{}\".format(\"shapes_worst.sqlite3\"), \n",
    "                            index_col=\"object_id\")\n",
    "\n",
    "df_random = pd.read_sql_table(\"table_1\", \n",
    "                            \"sqlite:///{}\".format(\"shapes_random.sqlite3\"), \n",
    "                            index_col=\"object_id\")\n",
    "\n",
    "df_best[\"type\"] = \"best\"\n",
    "df_worst[\"type\"] = \"worst\"\n",
    "df_random[\"type\"] = \"random\"\n",
    "\n",
    "df_all = pd.concat([df_best, df_worst, df_random])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that ids are distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(df_best.index) & set(df_worst.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(df_best.index) & set(df_random.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(df_worst.index) & set(df_random.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What fraction of objects have bad shapes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_shapes = df_all[[\n",
    "    \"gshape_sdss_flags\",\n",
    "    \"rshape_sdss_flags\",\n",
    "    \"ishape_sdss_flags\",\n",
    "    \"zshape_sdss_flags\",\n",
    "    \"yshape_sdss_flags\",\n",
    "]].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_best[[\n",
    "    \"gshape_sdss_flags\",\n",
    "    \"rshape_sdss_flags\",\n",
    "    \"ishape_sdss_flags\",\n",
    "    \"zshape_sdss_flags\",\n",
    "    \"yshape_sdss_flags\",\n",
    "]].max(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_worst[[\n",
    "    \"gshape_sdss_flags\",\n",
    "    \"rshape_sdss_flags\",\n",
    "    \"ishape_sdss_flags\",\n",
    "    \"zshape_sdss_flags\",\n",
    "    \"yshape_sdss_flags\",\n",
    "]].max(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_random[[\n",
    "    \"gshape_sdss_flags\",\n",
    "    \"rshape_sdss_flags\",\n",
    "    \"ishape_sdss_flags\",\n",
    "    \"zshape_sdss_flags\",\n",
    "    \"yshape_sdss_flags\",\n",
    "]].max(axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find largest galaxy (to set size)\n",
    "**remember:** shape is in units of `arcsec`$^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all[~bad_shapes][[\n",
    "    \"gshape_sdss_11\", \"gshape_sdss_12\", \"gshape_sdss_22\",\n",
    "    \"rshape_sdss_11\", \"rshape_sdss_12\", \"rshape_sdss_22\",\n",
    "    \"ishape_sdss_11\", \"ishape_sdss_12\", \"ishape_sdss_22\",\n",
    "    \"zshape_sdss_11\", \"zshape_sdss_12\", \"zshape_sdss_22\",\n",
    "    \"yshape_sdss_11\", \"yshape_sdss_12\", \"yshape_sdss_22\",\n",
    "]].max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get information on the largest galaxy\n",
    "[Note: this is only for galaxies with valid shapes in *every* band]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_largest = df_all[~bad_shapes][[\n",
    "    \"gshape_sdss_11\", \"gshape_sdss_12\", \"gshape_sdss_22\",\n",
    "    \"rshape_sdss_11\", \"rshape_sdss_12\", \"rshape_sdss_22\",\n",
    "    \"ishape_sdss_11\", \"ishape_sdss_12\", \"ishape_sdss_22\",\n",
    "    \"zshape_sdss_11\", \"zshape_sdss_12\", \"zshape_sdss_22\",\n",
    "    \"yshape_sdss_11\", \"yshape_sdss_12\", \"yshape_sdss_22\",\n",
    "]].max(axis=1).argmax()\n",
    "\n",
    "id_largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.loc[id_largest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
